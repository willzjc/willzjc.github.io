{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "cwd=os.getcwd().replace('\\\\','/')\n",
    "#github/willzjc.github.io\n",
    "if 'historical' not in cwd:\n",
    "    cwd=cwd+'/github/willzjc.github.io/python/historical_price/'\n",
    "os.chdir(cwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/Will-AMD/PycharmProjects/github/willzjc.github.io/python/historical_price/ref/\nDeal with this exception another time\nDeal with this exception another time\nDeal with this exception another time\nDeal with this exception another time\nDeal with this exception another time\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deal with this exception another time\nDeal with this exception another time\nDeal with this exception another time\nDeal with this exception another time\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           date    CPI\n0   01-Mar-2015  117.3\n1   01-Jun-2015  118.7\n2   01-Sep-2015  120.2\n3   01-Dec-2015  123.4\n4   01-Mar-2016  124.5\n5   01-Jun-2016  125.7\n6   01-Sep-2016  127.1\n7   01-Dec-2016  130.7\n8   01-Mar-2017  132.1\n9   01-Jun-2017  133.1\n10  01-Sep-2017  136.0\n11  01-Dec-2017  140.3\n         date       CPI\n0  2015-03-01 -1.415562\n1  2015-06-01 -1.219830\n2  2015-09-01 -1.010117\n3  2015-12-01 -0.562729\n4  2016-03-01 -0.408940\n5  2016-06-01 -0.241170\n6  2016-09-01 -0.045438\n7  2016-12-01  0.457873\n8  2017-03-01  0.653605\n9  2017-06-01  0.793414\n10 2017-09-01  1.198858\n11 2017-12-01  1.800035\n                 date      beer     scotch     vodka   whiskey      wine  \\\ndate                                                                       \n2015-04-15 2015-04-15 -0.496580  -0.143757 -0.403335 -0.335554 -0.924887   \n2015-04-16 2015-04-16 -0.560201  -0.021203 -0.495216 -0.354368  0.510849   \n2015-04-17 2015-04-17 -0.454165  -0.017911 -0.062464 -0.352035  0.774299   \n2015-04-20 2015-04-20 -0.184740  -0.125356 -0.447864 -0.137854 -0.634298   \n2015-04-21 2015-04-21 -0.325718  -0.150528 -0.125496  0.429433 -0.084892   \n2015-04-22 2015-04-22 -0.324754  -0.009429 -0.702812  0.349435 -0.508530   \n2015-04-23 2015-04-23 -0.529354   0.124336 -0.059328 -0.296195 -0.384748   \n2015-04-24 2015-04-24 -0.187872  -0.004194  0.597012 -0.353616  1.047678   \n2015-04-26 2015-04-26 -0.084488  -0.023732 -0.204520 -0.025646 -0.072977   \n2015-04-27 2015-04-27 -0.696841  -0.126980 -0.363196 -0.016540  2.907715   \n2015-04-28 2015-04-28 -0.696118   0.132918 -1.343159  0.269060  2.181572   \n2015-04-29 2015-04-29 -0.501158  -0.048550 -1.097619  0.250848  2.646251   \n2015-04-30 2015-04-30 -0.659488   0.001329 -0.421209  0.204339 -0.108060   \n2015-05-01 2015-05-01 -0.467902  -0.077355 -0.821348 -0.345112 -0.447632   \n2015-05-02 2015-05-02 -0.645752  -0.078261  0.008407 -0.041676 -0.147776   \n2015-05-03 2015-05-03 -0.696600  -0.110424  3.363488 -0.127544 -0.441675   \n2015-05-04 2015-05-04 -0.573696  -0.091791 -1.055285  0.100936 -0.077611   \n2015-05-05 2015-05-05 -0.614664  -0.124263  0.242344 -0.112794 -0.646874   \n2015-05-06 2015-05-06 -0.695155  -0.110192  0.128197  0.330545  0.662432   \n2015-05-08 2015-05-08 -0.562852  -0.033319 -0.787481  0.224132 -0.300021   \n2015-05-09 2015-05-09 -0.700456   0.070349 -0.052116  0.183945 -0.274867   \n2015-05-10 2015-05-10 -0.048581  -0.055817 -0.441906  0.019207  1.934671   \n2015-05-11 2015-05-11 -0.048581  10.325669  0.047605 -0.047696  1.223753   \n2015-05-12 2015-05-12 -0.590806  -0.072131 -0.652951 -0.345037 -0.582667   \n2015-05-13 2015-05-13 -0.704071  -0.169525 -0.212987 -0.210402 -0.104088   \n2015-05-16 2015-05-16 -0.693468  -0.060280  0.059522  0.371786  0.269243   \n2015-05-19 2015-05-19 -0.536343  -0.117923  0.285619  0.650462  1.304509   \n2015-05-20 2015-05-20 -0.586227  -0.106381  0.466246  0.303076  0.474443   \n2015-05-21 2015-05-21 -0.581890  -0.092630 -0.755495 -0.331039  4.081325   \n2015-05-22 2015-05-22 -0.272219  -0.127311 -0.522185 -0.185642  0.653827   \n...               ...       ...        ...       ...       ...       ...   \n2018-01-15 2018-01-15  0.137704  -0.095645 -0.198562 -0.420369  0.201726   \n2018-01-16 2018-01-16 -0.007613  -0.123335  0.273075 -0.445580  0.886828   \n2018-01-17 2018-01-17 -0.081114  -0.069071 -1.004797 -0.390943  0.040214   \n2018-01-18 2018-01-18 -0.118950  -0.113494  0.049173 -0.432711 -0.901719   \n2018-01-19 2018-01-19 -0.309572  -0.135341 -0.350652 -0.544016  0.029623   \n2018-01-20 2018-01-20 -0.380905  -0.131287  1.517394  0.763197  0.178558   \n2018-01-21 2018-01-21  0.017932  -0.144508 -0.941452  0.751909 -0.687252   \n2018-01-22 2018-01-22  0.116497  -0.129167 -0.209851 -0.085325  0.021680   \n2018-01-23 2018-01-23 -0.166906  -0.058689  0.753179 -0.147412 -0.064372   \n2018-01-24 2018-01-24 -0.245228  -0.122816 -0.898804 -0.525578 -0.081582   \n2018-01-25 2018-01-25  0.405684  -0.093017  0.403214 -0.143724  0.011751   \n2018-01-26 2018-01-26 -0.058461  -0.098937 -0.375112 -0.453933  0.165981   \n2018-01-27 2018-01-27  2.708335  -0.108458  1.577916  0.332728  1.081437   \n2018-01-28 2018-01-28  0.067335  -0.116708  0.740635 -0.138983  0.539974   \n2018-01-29 2018-01-29  0.310975  -0.103763  0.197814 -0.343682 -0.202054   \n2018-01-30 2018-01-30  0.076011  -0.155619  1.120391  0.025453  0.275201   \n2018-01-31 2018-01-31 -0.309331  -0.132381 -0.498352  0.229400 -0.266924   \n2018-02-01 2018-02-01  0.081794  -0.099401 -0.506192 -0.473425 -1.173112   \n2018-02-02 2018-02-02  0.775361  -0.164588 -0.225530 -0.308612  0.142152   \n2018-02-03 2018-02-03 -0.137024  -0.115659 -0.391105 -0.536415 -0.418507   \n2018-02-04 2018-02-04  0.433879  -0.126450 -1.421870 -0.336232 -0.147776   \n2018-02-05 2018-02-05  0.079866  -0.171303 -0.736366 -0.356175 -0.997700   \n2018-02-06 2018-02-06 -0.013637  -0.111749 -0.788421 -0.153131 -0.024656   \n2018-02-07 2018-02-07 -0.234383  -0.114135 -0.880303 -0.335404  1.391222   \n2018-02-08 2018-02-08 -0.084247  -0.132524 -1.034588 -0.221690  0.311607   \n2018-02-09 2018-02-09  0.277959  -0.139229 -0.804728 -0.111063 -0.956660   \n2018-02-11 2018-02-11  0.392911  -0.130349 -0.813822 -0.420745  0.307635   \n2018-02-12 2018-02-12  0.237714  -0.121745 -0.865250 -0.509624 -0.307964   \n2018-02-13 2018-02-13  0.142524  -0.119193 -0.288561 -0.457395  0.896095   \n2018-02-14 2018-02-14  0.101555  -0.136633 -0.657655 -0.487799  0.304988   \n\n             combined  average_sell_price  \ndate                                       \n2015-04-15  -2.032805           -0.722820  \n2015-04-16  -0.811793           -0.288655  \n2015-04-17  -0.099057           -0.035222  \n2015-04-20  -1.349942           -0.480009  \n2015-04-21  -0.226915           -0.080686  \n2015-04-22  -1.055252           -0.375224  \n2015-04-23  -1.010432           -0.359287  \n2015-04-24   0.969601            0.344768  \n2015-04-26  -0.362925           -0.129048  \n2015-04-27   1.503495            0.534609  \n2015-04-28   0.480185            0.170743  \n2015-04-29   1.102611            0.392064  \n2015-04-30  -0.867331           -0.308403  \n2015-05-01  -1.905087           -0.677406  \n2015-05-02  -0.798487           -0.283924  \n2015-05-03   1.753249            0.623416  \n2015-05-04  -1.497573           -0.532503  \n2015-05-05  -1.108329           -0.394097  \n2015-05-06   0.278640            0.099078  \n2015-05-08  -1.287680           -0.457870  \n2015-05-09  -0.682109           -0.242543  \n2015-05-10   1.241833            0.441568  \n2015-05-11  10.146545            3.607882  \n2015-05-12  -1.979410           -0.703834  \n2015-05-13  -1.236097           -0.439528  \n2015-05-16  -0.046933           -0.016688  \n2015-05-19   1.399536            0.497643  \n2015-05-20   0.486258            0.172902  \n2015-05-21   2.047061            0.727889  \n2015-05-22  -0.400127           -0.142276  \n...               ...                 ...  \n2018-01-15  -0.330973           -0.117687  \n2018-01-16   0.514684            0.183010  \n2018-01-17  -1.328416           -0.472355  \n2018-01-18  -1.338992           -0.476116  \n2018-01-19  -1.155711           -0.410945  \n2018-01-20   1.717704            0.610777  \n2018-01-21  -0.885226           -0.314766  \n2018-01-22  -0.252470           -0.089773  \n2018-01-23   0.278615            0.099069  \n2018-01-24  -1.653345           -0.587892  \n2018-01-25   0.515153            0.183177  \n2018-01-26  -0.723853           -0.257386  \n2018-01-27   4.933509            1.754245  \n2018-01-28   0.963642            0.342649  \n2018-01-29  -0.124142           -0.044142  \n2018-01-30   1.183483            0.420820  \n2018-01-31  -0.862478           -0.306678  \n2018-02-01  -1.914780           -0.680853  \n2018-02-02   0.193021            0.068634  \n2018-02-03  -1.410463           -0.501529  \n2018-02-04  -1.410231           -0.501446  \n2018-02-05  -1.924786           -0.684410  \n2018-02-06  -0.963060           -0.342442  \n2018-02-07  -0.152631           -0.054272  \n2018-02-08  -1.024684           -0.364355  \n2018-02-09  -1.529575           -0.543882  \n2018-02-11  -0.586140           -0.208418  \n2018-02-12  -1.382371           -0.491540  \n2018-02-13   0.153043            0.054419  \n2018-02-14  -0.772449           -0.274666  \n\n[927 rows x 8 columns]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     offset   clothes      food  furniture     total\n0      -150 -0.457397  0.194598   0.275466  0.025334\n1      -149 -0.052805  0.002868  -0.574141 -1.248157\n2      -148  0.010161  0.489916  -0.889631 -0.779107\n3      -147  0.244229  0.053040  -0.655714 -0.716890\n4      -146  0.453572 -0.399850  -0.334434 -0.561422\n5      -145  0.063708 -0.667226  -0.131057 -1.469151\n6      -144  0.199373 -0.035601  -0.158151  0.011242\n7      -143 -0.202886  0.059609   0.099210 -0.088135\n8      -142  0.178157 -0.257261   0.073821 -0.010567\n9      -141  0.229880 -0.135140   0.149621  0.488721\n10     -140 -0.096075 -0.736257   0.036017 -1.592631\n11     -139  0.130628 -0.614745  -0.339656 -1.647546\n12     -138 -0.015738 -0.313356   0.772569  0.886950\n13     -137 -0.286233 -0.732508  -0.521243 -3.079969\n14     -136 -0.525419 -0.155073  -0.991253 -3.343491\n15     -135  0.285465  0.016706   0.135542  0.875427\n16     -134  0.084840  0.360096  -0.031511  0.826851\n17     -133  0.269334 -0.310558   0.431265  0.780084\n18     -132 -0.150460  0.034816   0.286797  0.342306\n19     -131 -0.136163 -0.274703  -0.308054 -1.437842\n20     -130  0.109320 -0.396726  -0.065418 -0.705646\n21     -129  0.497971  0.370122  -0.947195 -0.158204\n22     -128  0.314431 -0.637042   0.264841 -0.115540\n23     -127  0.134547  0.149875  -0.793601 -1.018358\n24     -126  0.782829 -0.313595  -0.631332 -0.324195\n25     -125  0.178524 -0.161772  -0.204848 -0.376193\n26     -124  0.555860  0.084204   0.120882  1.521893\n27     -123 -0.298227  0.076586  -0.556867 -1.557016\n28     -122 -0.195595 -0.310130   0.732205  0.452960\n29     -121 -0.352666  0.692673  -0.073129  0.533756\n..      ...       ...       ...        ...       ...\n270     120 -0.698882  0.090551  -0.710150 -2.636964\n271     121  0.259231 -0.704913   0.082793 -0.725779\n272     122 -0.286777  0.708805   0.176772  1.197599\n273     123  0.342888  0.383486   0.207552  1.867853\n274     124 -0.583962  0.397529  -0.797349 -1.967562\n275     125 -0.646966  0.390505   0.690691  0.868461\n276     126 -0.605256  0.370510  -0.194251 -0.857992\n277     127 -0.465399  0.711384  -0.795920 -1.099870\n278     128 -0.628810  0.690294   0.022385  0.167738\n279     129 -0.619485 -0.322766  -0.816490 -3.517480\n280     130 -0.266873 -0.561928  -0.228512 -2.114625\n281     131 -0.367921  0.147718  -0.089028 -0.618463\n282     132 -0.547949  0.282473   0.166573 -0.197806\n283     133 -0.154701  0.546483   0.213059  1.209684\n284     134 -0.559156  0.413401   0.408211  0.524911\n285     135 -0.211479 -0.101070  -0.816881 -2.258861\n286     136 -0.163634  0.398616  -0.836595 -1.203225\n287     137 -0.692092 -0.289709   0.442960 -1.077681\n288     138 -0.075579  0.638553  -0.783573 -0.441197\n289     139 -0.537938  0.689670  -0.523741 -0.744018\n290     140 -0.535543 -0.350278   0.559520 -0.652603\n291     141 -0.350424 -0.187924   0.650505  0.224314\n292     142 -0.537500  0.238619  -0.282261 -1.162283\n293     143 -0.261041  0.640870  -0.280880  0.197898\n294     144  0.051912  0.291693   0.667756  2.022723\n295     145 -0.931687  0.847442  -0.354780 -0.878051\n296     146  0.054969  0.054294  -0.599129 -0.979732\n297     147 -0.128984  0.260131   0.307107  0.876509\n298     148 -0.864245  0.133996  -0.752839 -2.966175\n299     149  0.396493  0.237974  -0.330284  0.608364\n\n[300 rows x 5 columns]\n<bound method DatetimeIndexResampler.f of DatetimeIndexResampler [freq=<3 * MonthEnds>, axis=0, closed=right, label=right, convention=start, base=0]>\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "\n",
    "import plotly\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "import plotly.figure_factory as FF\n",
    "import cufflinks as cf\n",
    "\n",
    "plotly.tools.set_credentials_file(username='willzjc@gmail.com', api_key='nMap3MiO6fJx7AO5PnzT')\n",
    "\n",
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.interpolate import spline\n",
    "from matplotlib import dates as mdates\n",
    "import matplotlib\n",
    "# matplotlib.use('Qt5Agg')\n",
    "\n",
    "if sys.version_info[0] < 3:\n",
    "    from StringIO import StringIO\n",
    "else:\n",
    "    from io import StringIO\n",
    "\n",
    "def drawdf(df,draw_plot=True,product='unknown'):\n",
    "\n",
    "\n",
    "    #Normalize DF First\n",
    "\n",
    "    df['combined']=0\n",
    "\n",
    "    for eachitem in df.columns:\n",
    "        if not 'date' in eachitem:\n",
    "            df[eachitem] = (df[eachitem] - df[eachitem].mean()) / (df[eachitem].std())\n",
    "            df['combined']=df['combined']+df[eachitem]\n",
    "\n",
    "    # Get Total Rating based on average of\n",
    "    df['average_sell_price']=df[[c for c in df.columns[1:]]].mean(axis=1)\n",
    "\n",
    "    df.set_index(pd.DatetimeIndex(df['date'])).resample('3M').mean().plot()\n",
    "\n",
    "\n",
    "    # plot with all members\n",
    "    # df.set_index(pd.DatetimeIndex(df['date'])).resample('M').plot()\n",
    "\n",
    "    # df=df.replace('\\sUSD','',regex=True).apply(pd.to_numeric, errors='ignore')\n",
    "    # df['dateindex']=pd.to_datetime(df['date'])\n",
    "    df['date']=pd.to_datetime(df['date'])\n",
    "    df=df.set_index(pd.DatetimeIndex(df['date']))\n",
    "\n",
    "\n",
    "\n",
    "    cpi=pd.read_csv('ref/AUCPI',delimiter='\\t')\n",
    "\n",
    "    print cpi\n",
    "\n",
    "    cpi['date']=pd.to_datetime(cpi['date'])\n",
    "\n",
    "    cpi['CPI'] = (cpi['CPI'] - cpi['CPI'].mean()) / (cpi['CPI'].std())\n",
    "\n",
    "    # Timeshift\n",
    "    timeshift=30\n",
    "    print cpi\n",
    "    print df\n",
    "    templatecpi=cpi.copy()\n",
    "    templatedf = df.copy()\n",
    "    # for timeshift in [0,30,60,90,120]:\n",
    "    corrs={}\n",
    "    corrslist=[]\n",
    "    rng=range(-150,150)\n",
    "    if draw_plot:\n",
    "        rng=[-91,0,91]\n",
    "        \n",
    "    dfs=[]\n",
    "\n",
    "    for timeshift in rng:\n",
    "        cpi=templatecpi.copy()\n",
    "        df=templatedf.copy()\n",
    "\n",
    "\n",
    "        cpi['date'] = cpi['date'] - datetime.timedelta(days=(timeshift))\n",
    "        cpi=cpi.set_index(pd.DatetimeIndex(cpi['date']))\n",
    "\n",
    "        # Normalize CPI\n",
    "        # index = pd.date_range(cpi['date'].max(),cpi['date'].min())\n",
    "        # index = pd.date_range(cpi['date'])\n",
    "        # values = pd.Series(cpi.values, index=index)\n",
    "\n",
    "        # Read above link about the different Offset Aliases, S=Seconds\n",
    "        # resampled_values = values.resample('2.5D')\n",
    "        # cpi.diff()  # compute the difference between each point!\n",
    "        df.plot(y='average_sell_price',title=\"timeshift: \" + str(timeshift))\n",
    "        ax = cpi.plot(y='CPI')\n",
    "        df.resample('M').mean().plot(y='average_sell_price',ax=ax,title=\"timeshift: \" + str(timeshift))\n",
    "\n",
    "\n",
    "        # xnew = np.linspace(df['combined'].min(), df['combined'].max(), 300)  # 300 represents number of points to make between T.min and T.max\n",
    "\n",
    "        # power_smooth = spline(df['date'], df['combined'], xnew)\n",
    "\n",
    "        # plt.plot(xnew, power_smooth)\n",
    "\n",
    "        #\n",
    "\n",
    "        ##### Concat both tables #####\n",
    "        combined_df=pd.concat([cpi,df],axis=1, join='inner')\n",
    "        # print type(df),type(cpi)\n",
    "\n",
    "        # ##### Massaging Data #####\n",
    "        # ### resample\n",
    "        # df = df.resample('M').mean()\n",
    "        # df = df.resample('M')\n",
    "        # df = df.resample('D')\n",
    "        # # ### interpolate\n",
    "        # df= df.interpolate(method='cubic')\n",
    "\n",
    "        # df.plot(kind='bar')\n",
    "        # df['bad_rate'].plot(secondary_y=True)\n",
    "\n",
    "        # #### PLOTTING SECTION #####\n",
    "        # df = df.resample('M').mean()\n",
    "        # df = df.resample('D')\n",
    "        # tsint = df.interpolate(method='cubic')\n",
    "        # cpi=cpi.interpolate(method='cubic')\n",
    "        # tsint.plot()\n",
    "        # tsint.plot(y=['combined','average_sell_price'], use_index=True)\n",
    "        # tsint.plot()\n",
    "        # ax = cpi.plot(y='CPI', use_index=True,color='r',legend=True)\n",
    "        # tsint.plot.line(ax=ax,y='average_sell_price',use_index=True,secondary_y=True,legend=True)\n",
    "        # cpi_s.plot(ax=ax)\n",
    "        # result.plot(y='average_sell_price',kind='bar')\n",
    "        # result.plot(y='CPI',secondary_y=True)\n",
    "        corr=combined_df.CPI.corr(combined_df.average_sell_price)\n",
    "        corrs[timeshift]=corr\n",
    "        corrslist.append(corr)\n",
    "        \n",
    "        dfs.append(combined_df)\n",
    "\n",
    "        if draw_plot:\n",
    "            f, axarr = plt.subplots(2)\n",
    "\n",
    "            combined_df['positive']=combined_df['average_sell_price'] > 0\n",
    "\n",
    "            datefmt = mdates.DateFormatter('%Y-%m-%d')\n",
    "\n",
    "            axarr[0].format_xdata = datefmt\n",
    "            axarr[1].format_xdata = datefmt\n",
    "\n",
    "            axarr[0].xaxis.set_major_formatter(datefmt)\n",
    "            axarr[1].xaxis.set_major_formatter(datefmt)\n",
    "\n",
    "            combined_df.CPI.plot(ax=axarr[1], legend=True)\n",
    "            combined_df.average_sell_price.plot(legend=True, ax=axarr[0],kind='bar'\n",
    "             ,color=combined_df.positive.map({True: 'g', False: 'r'}),title='Timeshift: '+ str(timeshift) + ' days')\n",
    "\n",
    "\n",
    "            # combined_df.iplot(kind='scatter', filename='cufflinks-cf-simple-line')\n",
    "\n",
    "            # py.iplot([{\n",
    "            #     'x': combined_df.index,\n",
    "            #     'y': combined_df[col],\n",
    "            #     'name': col\n",
    "            # } for col in combined_df.columns if 'date' not in col ], filename='cufflinks-simple-line')\n",
    "\n",
    "    cdf=None\n",
    "    correlation_pickle='correl.pickle'\n",
    "    if os.path.exists(correlation_pickle):\n",
    "        cdf=pd.read_pickle(correlation_pickle)\n",
    "        # if not product in cdf.columns:\n",
    "        # cdf[product]=corrslist\n",
    "\n",
    "    else:\n",
    "        cdf=pd.DataFrame(columns=['offset',product])\n",
    "        cdf['offset']=range(-150,150)\n",
    "        cdf[product] = corrslist\n",
    "        # for k in corrs.keys():\n",
    "        #     cdf[k] = corrs[k]\n",
    "\n",
    "    cdf.to_pickle(correlation_pickle)\n",
    "    cdf['total']=0\n",
    "    for c in cdf.columns:\n",
    "        if 'offset' not in c:\n",
    "            cdf['total']=cdf['total']+cdf[c]\n",
    "\n",
    "\n",
    "\n",
    "    cdf.to_csv('correl.csv')\n",
    "\n",
    "    # print cdf\n",
    "\n",
    "    # if draw_plot:\n",
    "    #     plt.gcf().autofmt_xdate()\n",
    "    #     plt.show()\n",
    "\n",
    "def readfiles():\n",
    "\n",
    "    bol_recursive=False\n",
    "    df=None\n",
    "\n",
    "    basepath=os.getcwd().replace('\\\\','/') + '/' + 'ref' + '/'\n",
    "    print basepath\n",
    "\n",
    "    files=[]\n",
    "\n",
    "    for str_dirname, lst_subdirs, lst_files in os.walk(basepath):\n",
    "        if not bol_recursive:\n",
    "            while len(lst_subdirs) > 0:\n",
    "                lst_subdirs.pop()\n",
    "                for file in lst_files:\n",
    "                    if '.csv' in file and not 'corr' in file:\n",
    "                        with open(basepath+file,'rb') as f:\n",
    "                            files.append(f.read())\n",
    "                            f.close()\n",
    "\n",
    "    for f in files:\n",
    "\n",
    "        headers = {}\n",
    "        buffer=[]\n",
    "        headermode = True\n",
    "        for line in f.split('\\n'):\n",
    "            if headermode and 'Date,' in line:\n",
    "                headermode=False\n",
    "            elements=line.strip().split(',')\n",
    "            if len(elements) < 3 and len(elements) > 1:         # filter out header info\n",
    "                headers[elements[0].strip()]=elements[1].strip()\n",
    "            else:\n",
    "                linein=False\n",
    "                if len(elements)>1 and not headermode and '0.00 USD,0.00 USD' not in line:\n",
    "                    buffer.append(line)\n",
    "                    linein=True\n",
    "                # print f,linein,line\n",
    "\n",
    "        # Read file stream CSV\n",
    "        currentdf = pd.read_csv(StringIO('\\n'.join(buffer)))\n",
    "\n",
    "        # Replace Strings\n",
    "        currentdf = currentdf.replace('\\sUSD', '', regex=True).apply(pd.to_numeric, errors='ignore')\n",
    "        try:\n",
    "            if df==None:\n",
    "                df=pd.DataFrame(columns=['date'])\n",
    "                df['date'] = currentdf['Date']\n",
    "        except:\n",
    "            # TODO\n",
    "            print 'Deal with this exception another time'\n",
    "\n",
    "        # print currentdf.columns\n",
    "        df[headers['Keywords']] = currentdf['Average Selling Price']\n",
    "\n",
    "    df['combined']=0\n",
    "    df.to_csv('fileread.csv')\n",
    "    return df\n",
    "\n",
    "def main():\n",
    "    df=readfiles()\n",
    "    init_df=df.copy()\n",
    "    drawdf(df,draw_plot=True,product='alcohol')\n",
    "\n",
    "    init_df['datetime'] = pd.to_datetime(init_df['date'])\n",
    "    init_df=init_df.set_index(pd.DatetimeIndex(init_df['date']))\n",
    "\n",
    "    # init_df.set_index('date')\n",
    "\n",
    "    print init_df.resample('3M').mean\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
