{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A concept for forecasting inflation with online listed item prices\n",
    "Can we use online prices as a predictor of a nation's inflation and CPI?\n",
    "\n",
    "Resources online indicates that not only is this possible, but it has been done the past decade by those who has the right tools - http://www.mit.edu/~afc/papers/Cavallo_Online_Offline.pdf\n",
    "\n",
    "While it isn't entirely surprising that online and offline prices are similar.\n",
    "finding the correct data points in an ever growing pool of resources is the challenge that this model attempts to answer.\n",
    "\n",
    "Technolgy used: Jupyter Notebook, plot.ly, Python, d3js, Javascript\n",
    "<br><br><i>\n",
    "    <b>Output</b> = df\n",
    "</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Load Libraries for offline use\n",
    "# Dummy edit\n",
    "import os                                           # Fundamental file management libraries\n",
    "\n",
    "import numpy as np                                  # Base Array library used by Pandas\n",
    "import pandas as pd                                 # Pandas Matrix library\n",
    "\n",
    "import scipy as sp                                  # Required as the baseline data science module\n",
    "\n",
    "\n",
    "try:\n",
    "    from StringIO import StringIO                   # Formulating a string as a filestream\n",
    "except ImportError:\n",
    "    from io import StringIO\n",
    "    \n",
    "import plotly.tools as tls                          # Auxiliary Tools\n",
    "\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, iplot\n",
    "                                                    # plotly for offline use (i.e. no service fee)\n",
    "    \n",
    "from plotly.graph_objs import *                     # Different chart types\n",
    "init_notebook_mode()                                # Notebook \n",
    "\n",
    "import cufflinks as cf                              # Bridge from DataFrames to Plotly\n",
    "cf.go_offline()                                     # Required to use plotly offline (no account required).\n",
    "\n",
    "from sklearn import preprocessing                   # For natrix normalization\n",
    "\n",
    "# import seaborn as sns                             # For gradient color scales\n",
    "\n",
    "from IPython.display import display, HTML           # Formatting for Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "START_OFFSET=-150\n",
    "END_OFFSET=0\n",
    "### Formatting \n",
    "pd.options.display.float_format = '{:,.2f}'.format\n",
    "\n",
    "categorybasepath=os.getcwd()\n",
    "if 'historical_price' not in categorybasepath:\n",
    "    categorybasepath = categorybasepath +'/'+ 'willzjc.github.io/python/historical_price/ref/categories/'\n",
    "else:\n",
    "    categorybasepath = categorybasepath.split('historical_price')[0] + 'historical_price/ref/categories/'\n",
    "\n",
    "\n",
    "categorybasepath=categorybasepath.replace('\\\\','/')\n",
    "categories=list(set([x[0].replace(categorybasepath+'\\\\','').split('categories')[1].replace('/','').split('\\\\')[0].strip() \n",
    "                     for x in os.walk(categorybasepath)]))\n",
    "\n",
    "categories = [c for c in categories if (\n",
    "              'ipynb_checkpoints' not in c and\n",
    "              'Misc' not in c and not 'archive' in c\n",
    "    )]\n",
    "\n",
    "# print '\\n'.join([x for x in categories if len(x)>0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Priming data into model\n",
    "Nothing too complex, loading data into matrices\n",
    "<br><br><i>\n",
    "    <b>Output</b> = df, readFiles()\n",
    "</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Reads files\n",
    "\n",
    "global category,basepath\n",
    "\n",
    "def readfiles(categorybasepath):\n",
    "    global category,basepath\n",
    "    bol_recursive=False\n",
    "    df=None\n",
    "    global category\n",
    "\n",
    "    category='Food and non-alcoholic beverages'\n",
    "    category='Furnitures'\n",
    "#     category='Alcohol'\n",
    "#     category='Clothing and footwear'\n",
    "    basepath=categorybasepath+'/'+category+'/'\n",
    "    \n",
    "    files=[]\n",
    "\n",
    "    for str_dirname, lst_subdirs, lst_files in os.walk(basepath):\n",
    "        if not bol_recursive:\n",
    "            while len(lst_subdirs) >= 0:\n",
    "\n",
    "                for file in lst_files:\n",
    "                    if '.csv' in file and not 'corr' in file and not 'fileread' in file:\n",
    "#                         print 'Reading:',file\n",
    "                        with open(basepath+file,'rb') as f:\n",
    "                            buffer=f.read()\n",
    "                            files.append(buffer)\n",
    "                            f.close()\n",
    "                \n",
    "                if len(lst_subdirs) > 0: \n",
    "                    lst_subdirs.pop()\n",
    "                    if len(lst_subdirs)==0:\n",
    "                        break\n",
    "                else:\n",
    "                    break\n",
    "                    \n",
    "    for f in files:\n",
    "\n",
    "        headers = {}\n",
    "        buffer=[]\n",
    "        headermode = True\n",
    "        for line in f.split('\\n'):\n",
    "            if headermode and 'Date,' in line:\n",
    "                headermode=False\n",
    "            elements=line.strip().split(',')\n",
    "            if len(elements) < 3 and len(elements) > 1:         # filter out header info\n",
    "                headers[elements[0].strip()]=elements[1].strip()\n",
    "            else:\n",
    "                linein=False\n",
    "                if len(elements)>1 and not headermode and '0.00 USD,0.00 USD' not in line:\n",
    "                    buffer.append(line)\n",
    "                    linein=True\n",
    "                # print f,linein,line\n",
    "\n",
    "        # Read file stream CSV\n",
    "        currentdf = pd.read_csv(StringIO('\\n'.join(buffer)))\n",
    "\n",
    "        # Replace Strings\n",
    "        currentdf = currentdf.replace('\\sUSD', '', regex=True).apply(pd.to_numeric, errors='ignore')\n",
    "        try:\n",
    "            if df==None:\n",
    "                df=pd.DataFrame(columns=['date'])\n",
    "                df['date'] = currentdf['Date']\n",
    "        except Exception as e:\n",
    "            # TODO\n",
    "            do_nothing=True\n",
    "\n",
    "        df[headers['Keywords']] = currentdf['Average Selling Price']\n",
    "        df[headers['Keywords']+\"_sales\"] = currentdf['Total Sales']\n",
    "        df[headers['Keywords']+\"_weighting\"] = currentdf['Total Sales'] /  currentdf['Average Selling Price']\n",
    "\n",
    "    return df\n",
    "\n",
    "df = readfiles(categorybasepath)\n",
    "raw_df=df.copy()\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First pass of data enrichment\n",
    "1. Get all columns which are base values\n",
    "2. Find all columns which are other metrics\n",
    "3. Transforming raw matrix into a summary matrix\n",
    "<br><br><i>\n",
    "    <b>Output</b> = df, pricecolumns, salescolumns, weighcolumns\n",
    "</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "series_summary = df.copy()\n",
    "\n",
    "series_summary=series_summary.sum()[[c for c in series_summary.columns if 'date' not in c]].astype(int)\n",
    "dfs=pd.DataFrame(series_summary,columns=['value'])\n",
    "\n",
    "# Get all row names which are metrics\n",
    "metrics=[]\n",
    "ml=list(filter(lambda x: keyword in x, dfs.index.values) for keyword in ['sales','weigh'])\n",
    "for l in ml: metrics=metrics+l\n",
    "\n",
    "# Get all rows which are base values\n",
    "items=list(set(dfs.index.values) -  set(metrics))\n",
    "\n",
    "# Worked out mean and sum\n",
    "\n",
    "def getColumns(df,exclude_cols=None):\n",
    "    if not exclude_cols==None:\n",
    "        exclude_cols.append('date')\n",
    "    else:\n",
    "        exclude_cols=['date']\n",
    "    return [x for x in df.columns if x not in exclude_cols]\n",
    "\n",
    "# Getting column names of the different dimensions\n",
    "pricecolumns = [c for c in df.columns if (not 'date' in c and not 'sales' in c and     'weight' not in c)]\n",
    "salescolumns = [c for c in df.columns if (not 'date' in c and     'sales' in c and not 'weight' in c)]\n",
    "weighcolumns = [c for c in df.columns if (not 'date' in c and not 'sales' in c and     'weight' in c)]\n",
    "\n",
    "\n",
    "transformed_df=pd.DataFrame(columns=['item','avg_price','units_sold','revenue'])\n",
    "\n",
    "for i,item in enumerate(set(items)):                                    # Transform information to a new summary frame\n",
    "    avg_price  = item \n",
    "    units_sold = item +'_'+'weighting' \n",
    "    revenue    = item +'_'+'sales'\n",
    "    transformed_df.loc[len(transformed_df)] = [item\n",
    "           ,dfs.loc[dfs.index.isin([avg_price])]['value'][0]\n",
    "           ,dfs.loc[dfs.index.isin([units_sold])]['value'][0]\n",
    "           ,dfs.loc[dfs.index.isin([revenue])]['value'][0]\n",
    "          ]\n",
    "\n",
    "# Auxiliary Styling Function\n",
    "def highlight_max(s):\n",
    "    '''\n",
    "    highlight the maximum in a Series yellow.\n",
    "    '''\n",
    "    is_max = s == s.max()\n",
    "    return ['background-color: yellow' if v else '' for v in is_max]\n",
    "\n",
    "# transformed_df=transformed_df.set_index('item')\n",
    "transformed_df=transformed_df.sort_values(by=['revenue'],ascending=False)\n",
    "transformed_df['avg_price']=transformed_df['revenue'] / transformed_df['units_sold']\n",
    "\n",
    "# Aggregating for Total\n",
    "total_df = pd.DataFrame(transformed_df[filter(lambda x: 'item' not in x, transformed_df.columns)].sum(),columns=['total']).astype(int)\n",
    "\n",
    "total_df.loc[len(total_df)]=len(items)\n",
    "total_df.index.values[len(total_df)-1] = 'Category Count'\n",
    "\n",
    "#Formatting\n",
    "for c in ['units_sold']:\n",
    "    transformed_df[c]=transformed_df[c].map('{:,}'.format)\n",
    "\n",
    "for c in ['revenue','avg_price']:\n",
    "    transformed_df[c]=transformed_df[c].map('${:,.0f}'.format)\n",
    "\n",
    "# Final formatting\n",
    "total_df['total']=total_df['total'].map('{:,}'.format)\n",
    "\n",
    "#========================\n",
    "print('Aggregate Stats of categories')\n",
    "#Display Categorical Summary\n",
    "display(HTML(transformed_df.to_html(index=False)))\n",
    "print('\\n\\nTotal of all')\n",
    "#Display Total Aggregate Summary\n",
    "display(total_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First Plot - Seeing the data first hand\n",
    "No changing or modification of data yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Resampling and interpolate\n",
    "\n",
    "def interpolate_df(df, columns=None,frequency='M'):\n",
    "\n",
    "    sample_columns=df.columns\n",
    "\n",
    "    if not columns == None:\n",
    "        sample_columns = list(columns)\n",
    "        if 'date' not in sample_columns:\n",
    "            sample_columns.append('date')\n",
    "\n",
    "    ndf = df.copy()[sample_columns]\n",
    "\n",
    "    indexer = 'date'  # Only do this when the column date exists, set index column as date\n",
    "    if indexer in df.columns:\n",
    "        ndf['date'] = pd.to_datetime(df['date'])\n",
    "        ndf = ndf.set_index(pd.DatetimeIndex(df['date']))\n",
    "\n",
    "    ndf = ndf.resample(frequency).mean()\n",
    "    ndf = ndf.resample('D')\n",
    "    tsint = ndf.interpolate(method='cubic')\n",
    "    return tsint\n",
    "\n",
    "frequency='7D'\n",
    "\n",
    "# Show Price (interlolated to 1M)\n",
    "title='<b>Average Price ($)</b><br>Outliers not filtered<br>Interpolated and bucketing interval set to: <i>%s</i>'%(frequency)\n",
    "interpolate_df(df,columns=pricecolumns,frequency=frequency).iplot(title=title)\n",
    "\n",
    "# Show Units Sold (interlolated to 1M)\n",
    "title=\"<b>Units Sold</b><br>Outliers not filtered\"\n",
    "interpolate_df(df,columns=weighcolumns,frequency=frequency).iplot(title=title)\n",
    "\n",
    "# Show Sales Revenue (interlolated to 1M)\n",
    "title=\"<b>Sales revenue of items ($)</b><br>Outliers not filtered\"\n",
    "interpolate_df(df,columns=salescolumns,frequency=frequency).iplot(title=title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Normalization\n",
    "This section \n",
    "1. Normalizes data\n",
    "2. Removes any outliters above a certain percentile\n",
    "3. Smoothes out chart via more suitable bucketing interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#### Percentiel threshold\n",
    "percentile=0.90\n",
    "\n",
    "for c in df.columns:\n",
    "    if c not in ['date']:\n",
    "        q = df[c].quantile(percentile)\n",
    "        df[c] = df[df[c] < q][c]\n",
    "\n",
    "# df.iplot(y=getColumns(df),title='<b>Outliers Filtered</b><br>Period bucketing frequency unaltered')\n",
    "\n",
    "# interpolate, spine-smooth, and then plot \n",
    "\n",
    "interpolate_df(df,pricecolumns).iplot(title='<b>Price - Outliters Filtered ('+str(int(percentile*100))+ '%)</b><br>Interpolated and bucketing interval set to 1 month')\n",
    "interpolate_df(df,salescolumns).iplot(title='<b>Revenue - Outliters Filtered</b><br>Interpolated and bucketing interval set to 1 month')\n",
    "interpolate_df(df,weighcolumns).iplot(title='<b>Items Sold - Outliters Filtered</b><br>Interpolated and bucketing interval set to 1 month')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In this next step - we normalize all prices to be its own scale\n",
    "Bias is given to those categories which had a higher volume\n",
    "1. Average price of each category product accounted for\n",
    "2. As well as being weighted how many items of each category of the product is sold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "##### Make a copy of variables first\n",
    "input_df = df.copy()\n",
    "input_df = input_df.interpolate(method='linear', axis=0).ffill().bfill()\n",
    "\n",
    "##### Normalization for price #######\n",
    "\n",
    "# norm_columns = pricecolumns + weighcolumns                       # Normalize both price and weighting\n",
    "norm_columns = []                                                  # Normalize both price and weighting\n",
    "\n",
    "for c in (pricecolumns + weighcolumns):\n",
    "    if not 'date' in c:\n",
    "        norm_columns.append(c)\n",
    "\n",
    "display(input_df.head())\n",
    "x = input_df[norm_columns].values                                  # returns a numpy array\n",
    "min_max_scaler = preprocessing.MinMaxScaler()                      # Scaling\n",
    "x_scaled = min_max_scaler.fit_transform(x)                         # Fits curve\n",
    "ndf = pd.DataFrame(x_scaled)\n",
    "\n",
    "\n",
    "#### Normalized Values\n",
    "ndf['date']=pd.to_datetime(input_df['date'])\n",
    "ndf=ndf.set_index(pd.DatetimeIndex(input_df['date']))\n",
    "\n",
    "                                                                   # Fixes up columns\n",
    "ndf=ndf.drop(columns=['date'])\n",
    "ndf.columns=(norm_columns)\n",
    "\n",
    "                                                                   # Assign weighting based on sales\n",
    "for product in pricecolumns :\n",
    "    if product not in 'mean':\n",
    "        ndf[product]=ndf[product] * ndf[product + \"_weighting\"]    # Weighting Calculation\n",
    "#         ndf[product]=ndf[product] # * ndf[product + \"_weighting\"]    # No Weighting Calculation\n",
    "        ndf=ndf.drop(columns=[product + \"_weighting\"])\n",
    "\n",
    "ndf['mean']=ndf[pricecolumns].mean(axis=1)\n",
    "        \n",
    "ndf=interpolate_df(ndf)                                           # Interpolate first\n",
    "fig = tls.make_subplots(rows=2, cols=1, shared_xaxes=True)         # Sub Plotting, specify how many charts\n",
    "\n",
    "# for col in [c for c in getColumns(ndf) if c not in ['mean']]:\n",
    "for col in pricecolumns :\n",
    "    fig.append_trace({'x': ndf.index, 'y': ndf[col], 'type': 'scatter', 'name': col}, 1, 1)\n",
    "for col in ['mean']:\n",
    "    fig.append_trace({'x': ndf.index, 'y': ndf[col], 'type': 'bar', 'name': col}, 2, 1)\n",
    "\n",
    "\n",
    "fig.layout.title='Weighted Normalized prices chart in comparison to mean price'\n",
    "iplot(fig) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CPI stats\n",
    "Sourced from rba.gov.au, a csv file can be downloaded and used for our model's benchmark and reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Next is to get CPI\n",
    "cpi=pd.read_csv(basepath+'AUCPI',delimiter='\\t')\n",
    "title='Obtain CPI for the next step, including each point\\'s derivative'\n",
    "\n",
    "cpi['diff'] = cpi.CPI.diff() # Calculating difference from previous year\n",
    "cpi['diff'] = 100* cpi['diff'] / ((cpi['CPI'] + cpi['CPI'].shift(-1))/2)\n",
    "cpi.index=cpi['date']\n",
    "\n",
    "# Plotting two types of charts\n",
    "def plotdouble(df,metric1,metric2,color1='orange',color2='green'):\n",
    "    fig1 = df.iplot(columns=[metric1], kind='bar',asFigure=True,width=0.1,color=color1)   \n",
    "    fig2 = df.iplot(columns=[metric2],  kind='line',secondary_y=[metric2], asFigure=True,colors=color2,width=5)\n",
    "    fig2['data'].extend(fig1['data'])\n",
    "    fig2.layout.title=title\n",
    "    \n",
    "    return fig2\n",
    "\n",
    "iplot(plotdouble(cpi,'diff','CPI'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Interpolate\n",
    "icpi=cpi.set_index(pd.DatetimeIndex(cpi.index))\n",
    "icpi=icpi.resample('D').mean()\n",
    "# icpi.CPI=icpi.CPI.resample('D').mean()\n",
    "# icpi['CPI'].iplot()\n",
    "# print icpi.interpolate()\n",
    "# combined_df=pd.concat([cpi,df],axis=1)\n",
    "# combined_df\n",
    "# interpolation\n",
    "\n",
    "icpi.CPI=icpi.CPI.interpolate(type='spline')\n",
    "# icpi['CPI'].iplot(title='First interpolated spline for CPI')\n",
    "\n",
    "icpi['diff'] = 0\n",
    "icpi['diff'] = icpi.CPI.diff() # Calculating difference from previous year\n",
    "icpi['diff'] = 100* icpi['diff'] / ((icpi['CPI'] + icpi['CPI'].shift(-1))/2)\n",
    "\n",
    "# Filter out null\n",
    "icpi=icpi[icpi['diff'].notnull()]\n",
    "\n",
    "# sets index as the date for prices\n",
    "# also time serializes dataframe so as to allow concatenation\n",
    "\n",
    "#Either use prices or normalized prices\n",
    "prices=df.set_index(pd.DatetimeIndex(df['date'])).drop(columns=['date'])\n",
    "normalized_prices=ndf\n",
    "\n",
    "#Combine Prices\n",
    "cdf=pd.concat([icpi,normalized_prices],axis=1,join='inner')\n",
    "corr=cdf['diff'].corr(cdf['mean'])\n",
    "\n",
    "# Get Doubleplot figure\n",
    "fig=plotdouble(cdf,metric1='mean',metric2='diff')\n",
    "fig.layout.title='Final Result'\n",
    "\n",
    "mean_renamed='Price predictor'\n",
    "cpi_renamed ='CPI %'\n",
    "this_cdf=cdf.copy().rename(columns = {'mean': mean_renamed,'diff':cpi_renamed})\n",
    "fig_resampled=plotdouble(this_cdf.resample('M').mean(),metric1=cpi_renamed,metric2=mean_renamed)\n",
    "fig_resampled.layout.title='<b>'+ category + '</b><br>'+'Mean Price and CPI - Monthly' + '<br>Correlation: '+str(round(corr,2))\n",
    "\n",
    "iplot(fig_resampled)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time shift\n",
    "While the above looks correct, online prices are a lot more adaptive than RBA rates. \n",
    "Hence a timeshift is done to, each step is done per day, and the highest correlating shift is automatically chosen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def timeshift_series_plot(input_icpi,normalized_prices,offset,orientation=0,printoffset=True,sampling_rate='M',color1='orange',color2='blue'):\n",
    "    if offset==0 :printoffset=False\n",
    "        \n",
    "    global mean_renamed\n",
    "    global cpi_renamed\n",
    "    \n",
    "    icpi=input_icpi.copy()\n",
    "    \n",
    "    ref_icpi=icpi.copy()\n",
    "    ref_normalized_prices=normalized_prices.copy()\n",
    "    title='<b>'+ category + '</b><br>'+'Result - Monthly. '\n",
    "    if orientation == 0:                                                        # Time shift and filter out NaN values\n",
    "        title=title+' CPI shift: '\n",
    "        icpi=icpi.copy().shift(offset)\n",
    "        icpi=icpi[icpi.CPI.notnull()]\n",
    "        \n",
    "#         if printoffset: print ref_icpi.head(),'\\nShifted:\\n', icpi.head()\n",
    "\n",
    "    else:\n",
    "        title=title+' Price shift: '\n",
    "        normalized_prices=normalized_prices.shift(offset)\n",
    "        normalized_prices=normalized_prices[normalized_prices['mean'].notnull()]\n",
    "#         if printoffset: print ref_normalized_prices.head(),'\\n\\nShifted:\\n', normalized_prices.head()\n",
    "                                                                                \n",
    "    cdf=pd.concat([icpi,normalized_prices],axis=1)                              # Combine Dataframes: CPI and Prices\n",
    "    \n",
    "    if not sampling_rate == 'M':                                                # If we want to change sampling rate\n",
    "        cdf=cdf.resample(sampling_rate).mean().interpolate(kind='spine')    \n",
    "\n",
    "    corr=cdf['diff'].corr(cdf['mean'])                                          # Calculate Correlation\n",
    "    title= title + str(offset) +' days. Correlation: '+str(round(corr,2))\n",
    "\n",
    "    \n",
    "#     fig=plotdouble(cdf,metric1='mean',metric2='diff')                           \n",
    "\n",
    "    cdf=cdf.rename(columns = {'mean': mean_renamed,'diff':cpi_renamed})\n",
    "    fig_resampled=plotdouble(cdf.resample(sampling_rate).mean(),metric1=cpi_renamed,metric2=mean_renamed,color1=color1,color2=color2)\n",
    "    fig_resampled.layout.title=title\n",
    "    \n",
    "    iplot(fig_resampled)\n",
    "    return fig_resampled\n",
    "\n",
    "\n",
    "#find correlation of range\n",
    "correlation_matrx=pd.DataFrame(columns=['offset','correlation'])\n",
    "for i in range(START_OFFSET,END_OFFSET):                                                      # Looping through spectrum\n",
    "    licpi=icpi.copy().shift(i)\n",
    "    licpi=licpi[licpi.CPI.notnull()]\n",
    "\n",
    "    cdf=pd.concat([licpi,normalized_prices],axis=1,join='inner')\n",
    "    corr=cdf['diff'].corr(cdf['mean'])   # Calculate Correlation\n",
    "    \n",
    "    correlation_matrx.loc[len(correlation_matrx)]=[i,corr]\n",
    "\n",
    "correlation_matrx.iplot(y='correlation',x='offset',title='<b>'+ category + '</b><br>'+'Days Offset Correlation Spectrum')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "scdf=correlation_matrx.copy()\n",
    "highest_offset_row = scdf.loc[scdf['offset']> -388].loc[scdf['offset']<55].sort_values(['correlation'],ascending=False).head(n=1)\n",
    "h_offset = highest_offset_row['offset'].values[0].astype(int)\n",
    "\n",
    "double_chart=timeshift_series_plot(input_icpi=icpi,normalized_prices=normalized_prices,offset=h_offset,orientation=0\n",
    "                      ,sampling_rate='M'\n",
    "                      ,color1='yellow'\n",
    "                      ,color2='purple'\n",
    "                     )\n",
    "# print scdf\n",
    "# for r in scdf.iterrows():\n",
    "#     print r[1]['offset'],r[1]['correlation']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plot_final(icpi,normalized_prices,recalc_correlation=False,h_offset=h_offset):\n",
    "    bar_label='CPI % Change'\n",
    "    original_curve='Predictor'\n",
    "    new_curve='Time Shifted Predictor'\n",
    "\n",
    "    data1=icpi.copy()['diff']                                                              # CPI \n",
    "    data1=data1.to_frame()\n",
    "    data1=data1.rename(columns = {'diff': bar_label})\n",
    "\n",
    "    data2=normalized_prices.copy().shift(-h_offset)['mean'].to_frame()                     # Shifted Price Curve\n",
    "    data2=data2.rename(columns = {'mean': new_curve})\n",
    "    data2=data2[data2[new_curve].notnull()]\n",
    "    \n",
    "    h_offset_corr = highest_offset_row['correlation'].values                               # Correlation\n",
    "    if recalc_correlation:\n",
    "        h_offset_corr=data2[new_curve].corr(icpi['diff'])\n",
    "\n",
    "\n",
    "    data3=normalized_prices.copy()['mean'].to_frame()                                      # Prices\n",
    "    data3=data3.rename(columns = {'mean': original_curve})\n",
    "\n",
    "    combined_frame=pd.concat([data1,data2,data3[original_curve]],axis=1)      # Combined\n",
    "    \n",
    "\n",
    "        \n",
    "    title='<b> %s </b><br>Interval: Monthly    Offset: %s    Correlation: %s'%(category,h_offset,round(h_offset_corr,2))\n",
    "    color1='orange'\n",
    "    color2='green'\n",
    "\n",
    "    # Comparing a substring of 1 list to another list\n",
    "    # Lambda combined with any()\n",
    "    # combined_frame.iplot(columns=filter(lambda x: not any(n in x for n in ['diff','CPI']), combined_frame.columns))\n",
    "\n",
    "#     combined_frame=combined_frame.resample('W').mean().interpolate(kind='spine')   \n",
    "    combined_frame=combined_frame.resample('W').mean()\n",
    "\n",
    "    fig1 = combined_frame.iplot(columns=[bar_label], kind='bar',asFigure=True,width=5,color=color1)   \n",
    "\n",
    "    fig2 = combined_frame.iplot(columns=[original_curve]\n",
    "        ,kind='line',secondary_y=[original_curve]\n",
    "        ,asFigure=True,colors=['green'],width=5,dash='dot'\n",
    "        )\n",
    "\n",
    "    fig3 = combined_frame.iplot(columns=[new_curve]\n",
    "        ,kind='line',secondary_y=[new_curve]\n",
    "        ,asFigure=True,colors=['purple'],width=5\n",
    "        )\n",
    "\n",
    "    fig2['data'].extend(fig1['data'])\n",
    "    fig3['data'].extend(fig2['data'])\n",
    "    fig3.layout.title=title\n",
    "    iplot(fig3)\n",
    "\n",
    "plot_final(icpi,normalized_prices)\n",
    "    \n",
    "def find_highest_correlation(icpi,normalized_prices,offset_start=-250,offset_end=0,target_column='mean'):\n",
    "#     print normalized_prices.to_frame().columns\n",
    "    target_frame=normalized_prices.copy().to_frame()\n",
    "    \n",
    "    correlation_matrx=pd.DataFrame(columns=['offset','correlation'])\n",
    "    corrmax=0\n",
    "    corroffset=0\n",
    "    for i in range(offset_start,offset_end):\n",
    "        licpi=icpi.copy().shift(i)\n",
    "        licpi=licpi[licpi['diff'].notnull()]\n",
    "        cdf=pd.concat([licpi,normalized_prices],axis=1,join='inner')        \n",
    "        corr=cdf['diff'].corr(cdf[target_column])                                  # Calculate Correlation\n",
    "        correlation_matrx.loc[len(correlation_matrx)]=[i,corr]\n",
    "        if corrmax<corr:\n",
    "            corroffset=i\n",
    "            corrmax=corr\n",
    "    \n",
    "    correlation_matrx=correlation_matrx.sort_values('correlation',ascending=False)\n",
    "    h_c_offset = correlation_matrx.head(1)['offset'].values[0]\n",
    "    target_frame=target_frame.shift(-int(corroffset))\n",
    "    target_frame=target_frame[target_frame[c].notnull()]\n",
    "#     target_frame=target_frame[target_frame[c].notnull()]\n",
    "\n",
    "    return correlation_matrx,target_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print 'Highest Offset is: %s'%(h_offset)\n",
    "ref_normalized_prices=normalized_prices.copy()\n",
    "ref_cpi = icpi.copy()['diff'].to_frame()\n",
    "ref_cpi = ref_cpi.shift(h_offset)\n",
    "#\n",
    "individual_correlation_df=pd.DataFrame(columns=['item','correlation','type','highest-c','offset'])\n",
    "\n",
    "acceptable_columns=[]\n",
    "shifted_frames=[]\n",
    "for c in [x for x in ref_normalized_prices.columns if  'mean' not in x]:\n",
    "    correlation=ref_normalized_prices[c].corr(ref_cpi['diff'])\n",
    "    status=''\n",
    "\n",
    "    cm,tf=find_highest_correlation(ref_cpi,ref_normalized_prices[c],offset_start=START_OFFSET,offset_end=END_OFFSET,target_column=c)\n",
    "    highest_c  = cm.head(1)['correlation'].values[0]\n",
    "    h_c_offset = cm.head(1)['offset'].values[0]\n",
    "    threshold=0.55\n",
    "    if correlation > threshold:\n",
    "        acceptable_columns.append(c)\n",
    "        status='immediate'\n",
    "    elif highest_c > threshold:\n",
    "        \n",
    "#         if int(h_c_offset)\n",
    "        \n",
    "        acceptable_columns.append(c)\n",
    "        status='long range'\n",
    "        \n",
    "    \n",
    "    shifted_frames.append(tf)\n",
    "    individual_correlation_df.loc[len(individual_correlation_df)]=[c,correlation,status,highest_c,h_c_offset]\n",
    "\n",
    "cat_summary=transformed_df.copy()\n",
    "cat_summary=cat_summary.set_index('item')\n",
    "individual_correlation_df=individual_correlation_df.set_index('item')\n",
    "individual_correlation_df=pd.concat([cat_summary,individual_correlation_df],axis=1)\n",
    "# individual_correlation_df=individual_correlation_df.sort_values('correlation',ascending=False)\n",
    "\n",
    "fcdf=None\n",
    "fcdf_init=False\n",
    "for f in shifted_frames:\n",
    "#     display(f)\n",
    "#     display(icpi)\n",
    "    fcpi=pd.concat([f,icpi['diff']],axis=1,join='inner')\n",
    "    product = f.columns[0]\n",
    "    print product\n",
    "    fcorr=fcpi[product].corr(fcpi['diff']) \n",
    "    fcpi.iplot(title='Correlation=%s'%(fcorr))\n",
    "    if not fcdf_init:\n",
    "        fcdf=f\n",
    "        fcdf_init=True\n",
    "    else:\n",
    "        fcdf = pd.concat([f,fcdf],axis=1)\n",
    "        \n",
    "\n",
    "ref_normalized_prices['mean']=ref_normalized_prices[acceptable_columns].mean(axis=1)\n",
    "# plot_final(icpi=icpi,normalized_prices=ref_normalized_prices[acceptable_columns+['mean']],recalc_correlation=True)\n",
    "\n",
    "fcdf['mean']=((fcdf[acceptable_columns].mean(axis=1)).to_frame())\n",
    "\n",
    "display(individual_correlation_df.sort_values('highest-c',ascending=False))\n",
    "fcdf=fcdf.rename(columns = {1 : 'mean'})\n",
    "plot_final(icpi=icpi,normalized_prices=fcdf[acceptable_columns+['mean']],recalc_correlation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
